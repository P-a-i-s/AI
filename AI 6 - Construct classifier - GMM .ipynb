{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import patches \n",
    " \n",
    "from sklearn import datasets \n",
    "from sklearn.mixture import GMM \n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cross_validation import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the iris dataset \n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split dataset into training and testing (80/20 split) \n",
    "indices = StratifiedKFold(iris.target, n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take the first fold \n",
    "train_index, test_index = next(iter(indices)) \n",
    " \n",
    "# Extract training data and labels \n",
    "X_train = iris.data[train_index] \n",
    "y_train = iris.target[train_index] \n",
    " \n",
    "# Extract testing data and labels \n",
    "X_test = iris.data[test_index] \n",
    "y_test = iris.target[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.cross_validation.StratifiedKFold(labels=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
       " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
       " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
       " 2 2], n_folds=5, shuffle=False, random_state=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the number of classes \n",
    "num_classes = len(np.unique(y_train))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59, 100, 101, 102, 103, 104, 105,\n",
       "       106, 107, 108, 109])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:52: DeprecationWarning: Class GMM is deprecated; The class GMM is deprecated in 0.18 and will be  removed in 0.20. Use class GaussianMixture instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Build GMM \n",
    "classifier = GMM(n_components=num_classes, covariance_type='full',  \n",
    "        init_params='wc', n_iter=20) \n",
    "#wv - weight & covariance params will be updated during the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GMM in module sklearn.mixture.gmm:\n",
      "\n",
      "class GMM(_GMMBase)\n",
      " |  Legacy Gaussian Mixture Model\n",
      " |  \n",
      " |  .. deprecated:: 0.18\n",
      " |      This class will be removed in 0.20.\n",
      " |      Use :class:`sklearn.mixture.GaussianMixture` instead.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GMM\n",
      " |      _GMMBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(*args, **kwargs)\n",
      " |      DEPRECATED: The class GMM is deprecated in 0.18 and will be  removed in 0.20. Use class GaussianMixture instead.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _GMMBase:\n",
      " |  \n",
      " |  aic(self, X)\n",
      " |      Akaike information criterion for the current model fit\n",
      " |      and the proposed data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array of shape(n_samples, n_dimensions)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      aic: float (the lower the better)\n",
      " |  \n",
      " |  bic(self, X)\n",
      " |      Bayesian information criterion for the current model fit\n",
      " |      and the proposed data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array of shape(n_samples, n_dimensions)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bic: float (the lower the better)\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Estimate model parameters with the EM algorithm.\n",
      " |      \n",
      " |      A initialization step is performed before entering the\n",
      " |      expectation-maximization (EM) algorithm. If you want to avoid\n",
      " |      this step, set the keyword argument init_params to the empty\n",
      " |      string '' when creating the GMM object. Likewise, if you would\n",
      " |      like just to do an initialization, set n_iter=0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like, shape (n, n_features)\n",
      " |          List of n_features-dimensional data points.  Each row\n",
      " |          corresponds to a single data point.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  fit_predict(self, X, y=None)\n",
      " |      Fit and then predict labels for data.\n",
      " |      \n",
      " |      Warning: Due to the final maximization step in the EM algorithm,\n",
      " |      with low iterations the prediction may not be 100%  accurate.\n",
      " |      \n",
      " |      .. versionadded:: 0.17\n",
      " |         *fit_predict* method in Gaussian Mixture Model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape = (n_samples,) component memberships\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict label for data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape = (n_samples,) component memberships\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Predict posterior probability of data under each Gaussian\n",
      " |      in the model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      responsibilities : array-like, shape = (n_samples, n_components)\n",
      " |          Returns the probability of the sample for each Gaussian\n",
      " |          (state) in the model.\n",
      " |  \n",
      " |  sample(self, n_samples=1, random_state=None)\n",
      " |      Generate random samples from the model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n_samples : int, optional\n",
      " |          Number of samples to generate. Defaults to 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : array_like, shape (n_samples, n_features)\n",
      " |          List of samples\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Compute the log probability under the model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like, shape (n_samples, n_features)\n",
      " |          List of n_features-dimensional data points. Each row\n",
      " |          corresponds to a single data point.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      logprob : array_like, shape (n_samples,)\n",
      " |          Log probabilities of each data point in X\n",
      " |  \n",
      " |  score_samples(self, X)\n",
      " |      Return the per-sample likelihood of the data under the model.\n",
      " |      \n",
      " |      Compute the log probability of X under the model and\n",
      " |      return the posterior distribution (responsibilities) of each\n",
      " |      mixture component for each element of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X: array_like, shape (n_samples, n_features)\n",
      " |          List of n_features-dimensional data points. Each row\n",
      " |          corresponds to a single data point.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      logprob : array_like, shape (n_samples,)\n",
      " |          Log probabilities of each data point in X.\n",
      " |      \n",
      " |      responsibilities : array_like, shape (n_samples, n_components)\n",
      " |          Posterior probabilities of each mixture component for each\n",
      " |          observation\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.means_ = np.array([X_train[y_train == i].mean(axis=0) \n",
    "                              for i in range(num_classes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.0425,  3.445 ,  1.4675,  0.25  ],\n",
       "       [ 5.895 ,  2.745 ,  4.2325,  1.3125],\n",
       "       [ 6.5925,  2.9825,  5.4975,  2.0225]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The functon distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GMM(covariance_type='full', init_params='wc', min_covar=0.001, n_components=3,\n",
       "  n_init=1, n_iter=20, params='wmc', random_state=None, tol=0.001,\n",
       "  verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
