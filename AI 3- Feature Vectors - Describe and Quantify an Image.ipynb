{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Vectors:\n",
    "- A feature vector is an abstraction of the image itself and at the most basic level, is simply a list of numbers used to represent the image\n",
    "\n",
    "#### Steps:\n",
    "- first step of building any image search engine is to define your image descriptor. \n",
    "- Once we have defined our image descriptor we can apply our descriptor to an image. \n",
    "- The output of the image descriptor is our feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198, 254, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "image = cv2.imread(\"/Users/apple/Downloads/charizard.png\")\n",
    "image.shape\n",
    "#http://www.pyimagesearch.com/2014/03/03/charizard-explains-describe-quantify-image-using-feature-vectors/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Pixel Feature Vectors\n",
    "basic color feature vector you can use is the raw pixel intensities \n",
    "\n",
    "\n",
    "- What image descriptor am I using? I am using a raw pixel descriptor.\n",
    "- What is the excepted output of my descriptor? \n",
    "A list of numbers corresponding to the raw RGB pixel intensities of my image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150876,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = image.flatten()\n",
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([255, 255, 255, ..., 255, 255, 255], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our flattened array has a shape of 150,876 because there exists 198 x 254 = 50,292 pixels in the image with 3 values\n",
    "#per pixel, thus 50,292 x 3 = 150,876"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Mean\n",
    "- A simple method to quantify the color of an image is to compute the mean of each of the color channels\n",
    "\n",
    "\n",
    "- What image descriptor am I using? A color mean descriptor.\n",
    "- What is the expected output of my image descriptor? The mean value of each channel of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181.12238527002307, 199.18315040165433, 206.514296508391, 0.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = cv2.mean(image)\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using the cv2.mean method\n",
    "\n",
    "#This method returns a tuple with four values, our color features.\n",
    "# The first value is the mean of the blue channel, the second value the mean of the green channel\n",
    "#and the third value is the mean of red channel. <<Remember, OpenCV stores RGB images as a NumPy array>>\n",
    "#but in reverse order. We actually read them backwards in BGR order, \n",
    "#hence the blue value comes first, then the green, and finally the red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181.12238527002307, 199.18315040165433, 206.514296508391)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = means[:3]\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Mean and Standard Deviation\n",
    "- compute both the mean and standard deviation of each channel\n",
    "\n",
    "- What image descriptor am I using? A color mean and standard deviation descriptor.\n",
    "- What is the expected output of my image descriptor? The mean and standard deviation of each channel of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 181.12238527],\n",
       "        [ 199.1831504 ],\n",
       "        [ 206.51429651]]), array([[ 80.67819854],\n",
       "        [ 65.41130384],\n",
       "        [ 77.77899992]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(means, stds) = cv2.meanStdDev(image)\n",
    "means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grab both the mean and standard deviation of each channel, we use the cv2.meanStdDev\n",
    "# returns a tuple - one for the means and one for the standard deviations, respectively\n",
    "#  this list of numbers serves as our color features\n",
    "# combine the means and standard deviations into a single color feature vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 181.12238527,  199.1831504 ,  206.51429651,   80.67819854,\n",
       "         65.41130384,   77.77899992])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "stats = np.concatenate([means, stds]).flatten()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# our feature vector stats has six entries rather than three. \n",
    "# We are now representing the mean of each channel as well as the standard deviation of each channel in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D color histogram to describe our image.\n",
    "\n",
    "- What image descriptor am I using? A 3D color histogram.\n",
    "- What is the expected output of my image descriptor? A list of numbers used to characterize the color distribution of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8, 8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How can we use this as a feature vector if itâ€™s multi-dimensional?\n",
    "# Ans:  We should flatten it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = hist.flatten()\n",
    "hist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# By defining our image descriptor as a 3D color histogram we can extract a list of numbers (i.e. our feature vector)\n",
    "# to represent the distribution of colors in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
